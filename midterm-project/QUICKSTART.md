# Quick Start Guide

## ğŸ“¦ Installation

### Option 1: Local Development

```bash
# Clone repository
git clone <repo-url>
cd market-profile-ml

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Verify installation
python -c "import yfinance, sklearn, fastapi; print('âœ… Ready to go!')"
```

### Option 2: Using Makefile

```bash
make install       # Install dependencies
make dev           # Install with dev tools (Jupyter, pytest)
```

---

## ğŸš€ Running the Complete Pipeline

### 1. Train the Model

```bash
python scripts/train.py --config configs/train.yaml
```

**What happens:**
- Downloads Bitcoin hourly data from Yahoo Finance (cached locally)
- Engineers Market Profile features (POC, VAH, VAL, etc.)
- Trains 3 models: Logistic Regression, Random Forest, XGBoost
- Evaluates models and saves best one to `models/`
- Outputs metrics to `models/metrics.json`

**Time:** ~5-10 minutes first run, ~2 minutes with cache

**Output:**
```
INFO - Loading data...
INFO - Loaded 8760 hourly candles
INFO - Engineering features...
INFO - Total samples: 365
INFO - Training XGBoost...
INFO - Best model: xgboost (AUC: 0.6720)
INFO - Training completed successfully!
```

---

## ğŸ¤– Making Predictions

### Option A: From CSV File

```bash
python scripts/predict.py --input examples/sample_input.csv
```

### Option B: From JSON File

```bash
python scripts/predict.py --input examples/sample_prediction_request.json
```

### Output Example

```
{
  "predictions": [1, 0, 1],
  "probabilities": [0.672, 0.421, 0.598],
  "num_samples": 3
}
```

---

## ğŸŒ Running the API

### Local Development

```bash
# Option 1: Direct
python scripts/serve.py

# Option 2: Using uvicorn
uvicorn scripts.serve:app --host 0.0.0.0 --port 9696 --reload

# Option 3: Using Make
make serve
```

API runs at: `http://localhost:9696`

### API Endpoints

**Health Check:**
```bash
curl http://localhost:9696/health
```

**Make a Prediction:**
```bash
curl -X POST http://localhost:9696/predict \
  -H "Content-Type: application/json" \
  -d @examples/sample_prediction_request.json
```

**Interactive Docs:**
```
http://localhost:9696/docs
```

---

## ğŸ³ Docker Deployment

### Option 1: Build and Run

```bash
# Build image
docker build -t market-profile-ml:latest .

# Run container
docker run -it -p 9696:9696 \
  -v $(pwd)/models:/app/models \
  -v $(pwd)/data:/app/data \
  market-profile-ml:latest
```

### Option 2: Docker Compose (Recommended)

```bash
# Start service
docker-compose up -d

# View logs
docker-compose logs -f

# Stop service
docker-compose down
```

API available at: `http://localhost:9696`

---

## ğŸ“” Jupyter Notebook

```bash
jupyter notebook notebook.ipynb
```

The notebook includes:
- Data exploration and visualization
- Feature engineering walkthrough
- Model training and comparison
- Performance evaluation
- Feature importance analysis

---

## ğŸ§ª Running Tests

```bash
# All tests
pytest tests/ -v

# With coverage
pytest tests/ -v --cov=src --cov=scripts

# Specific test
pytest tests/test_market_profile.py -v
```

---

## ğŸ“Š Project Structure

```
market-profile-ml/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ train.py          # Model training script
â”‚   â”œâ”€â”€ predict.py        # Batch prediction script
â”‚   â””â”€â”€ serve.py          # FastAPI service
â”œâ”€â”€ notebook.ipynb        # Jupyter notebook
â”œâ”€â”€ Dockerfile            # Container configuration
â”œâ”€â”€ docker-compose.yml    # Multi-container setup
â”œâ”€â”€ requirements.txt      # Python dependencies
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ loader.py     # Data loading utilities
â”‚   â””â”€â”€ features/
â”‚       â””â”€â”€ market_profile.py  # Feature engineering
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ train.yaml        # Training configuration
â”‚   â””â”€â”€ api_schema.json   # API input schema
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Raw OHLCV data (auto-cached)
â”‚   â””â”€â”€ processed/        # Engineered features
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ best_model.pkl    # Trained model artifact
â”‚   â”œâ”€â”€ preprocessor.pkl  # Scaler artifact
â”‚   â”œâ”€â”€ feature_names.json
â”‚   â””â”€â”€ metrics.json
â”‚
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ sample_input.csv
â”‚   â””â”€â”€ sample_prediction_request.json
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ test_market_profile.py
    â””â”€â”€ test_api.py
```

---

## ğŸ”§ Configuration

Edit `configs/train.yaml` to customize:

```yaml
data:
  ticker: "BTC-USD"        # Change cryptocurrency/stock
  period: "2y"             # Data period (1y, 2y, 5y, etc)
  interval: "1h"           # Candle interval (1h, 4h, 1d, etc)

model:
  test_size: 0.2           # Test set proportion
  random_state: 42         # Reproducibility seed
```

---

## ğŸ“ˆ Performance Metrics

After training, check `models/metrics.json`:

```json
{
  "model_name": "xgboost",
  "auc": 0.6720,
  "precision": 0.6450,
  "recall": 0.5890,
  "f1": 0.6150,
  "confusion_matrix": [[52, 18], [15, 38]]
}
```

---

## ğŸ› Troubleshooting

### "Model not found" error
```bash
# Train model first
python scripts/train.py --config configs/train.yaml
```

### Port 9696 already in use
```bash
# Use different port
uvicorn scripts.serve:app --port 8000
```

### Yahoo Finance download fails
```bash
# Check connection or wait (rate limiting)
# Data is cached, so retry later
```

### Out of memory
```bash
# Reduce data period in configs/train.yaml
# Or run on machine with more RAM
```

---

## ğŸ“š Documentation

- **Full README:** `README.md` - Complete project documentation
- **Data Documentation:** `data/README.md` - Schema and preprocessing
- **API Schema:** `configs/api_schema.json` - Input specifications

---

## ğŸ¯ Common Workflows

### Development Cycle

```bash
make install              # First time setup
python scripts/train.py   # Train model
make test                 # Run tests
make serve                # Start API
# Make changes...
docker build -t market-profile-ml .  # Build image
docker run -p 9696:9696 market-profile-ml  # Test container
```

### Production Deployment

```bash
# Prepare
make install
python scripts/train.py --config configs/train.yaml

# Build image
docker build -t market-profile-ml:prod .

# Deploy
docker run -d -p 9696:9696 \
  -v /path/to/models:/app/models \
  market-profile-ml:prod

# Monitor
curl http://localhost:9696/health
```

### Model Retraining

```bash
# Retrain with new data
rm data/raw/BTC-USD_2y_1h.parquet  # Clear cache
python scripts/train.py --config configs/train.yaml

# Update API (restart if using Docker)
docker-compose restart api
```

---

## ğŸ“ Support

1. Check README.md for detailed documentation
2. Review test files for usage examples
3. Check logs for error details
4. Open GitHub issue with error message

---

## âœ… Verification Checklist

After setup, verify everything works:

```bash
âœ“ python -c "import yfinance, sklearn, fastapi"
âœ“ python scripts/train.py --config configs/train.yaml  
âœ“ python scripts/predict.py --input examples/sample_input.csv
âœ“ python scripts/serve.py  # Should start without errors
âœ“ curl http://localhost:9696/health
âœ“ pytest tests/ -v  # All tests pass
âœ“ docker-compose up -d  # Containers start
```

---

## ğŸ“ Learning Resources

- **Market Profile Theory:** See README.md â†’ References
- **ML Zoomcamp:** Course materials at datatalksclub.com
- **Technical Analysis:** investopedia.com and tradingview.com



